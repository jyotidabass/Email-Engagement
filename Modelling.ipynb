{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Email Engagement Prediction**"
      ],
      "metadata": {
        "id": "bbDZJIhxO5rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction:**\n",
        "\n",
        "In this notebook, we aim to build a machine learning model to predict the likelihood of email engagement, specifically focusing on whether the email will be 'clicked' or not. We will explore different ML algorithms to achieve the best possible accuracy."
      ],
      "metadata": {
        "id": "q-_fMAH8PCnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents:\n",
        "\n",
        "1. [**Loading and Preprocessing Data**](#loading-and-preprocessing-data)\n",
        "2. [**Feature Selection and Splitting**](#feature-selection-and-splitting)\n",
        "3. [**Model Training and Evaluation**](#model-training-and-evaluation)\n",
        "4. [**Conclusion**](#conclusion)\n"
      ],
      "metadata": {
        "id": "gEPnwpvvPOy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading and Preprocessing Data <a name=\"loading-and-preprocessing-data\"></a>\n"
      ],
      "metadata": {
        "id": "N-E4-gvIPT4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "55rnQ7SZZLA6",
        "outputId": "d731b64b-8481-4436-c048-275a74dfa9e8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "y2pMaDB_JTDD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "\n",
        "# Function to load and preprocess the dataset\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Add any additional preprocessing steps as needed\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Selection and Splitting <a name=\"feature-selection-and-splitting\"></a>"
      ],
      "metadata": {
        "id": "sdL4JS4qPaXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split the dataset into features and target variable\n",
        "def split_features_target(df, target_column, feature_columns):\n",
        "    X = df[feature_columns]  # Features\n",
        "    y = df[target_column]  # Target variable\n",
        "    return X, y\n",
        "\n",
        "# Function to split the dataset into train and test sets\n",
        "def split_train_test(X, y, test_size=0.2, random_state=42):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "_R8uZgQMPi-5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model Training and Evaluation <a name=\"model-training-and-evaluation\"></a>"
      ],
      "metadata": {
        "id": "PNRFtMr6Pljw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and train the machine learning model\n",
        "def train_model1(X_train, y_train):\n",
        "    model = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Standardize features\n",
        "        ('classifier', RandomForestClassifier(random_state=42))  # RandomForestClassifier\n",
        "    ])\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model on the test set\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "    return accuracy, classification_rep, confusion_mat"
      ],
      "metadata": {
        "id": "rSxwCliGKJM5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "file_path = '/content/email_data.csv'\n",
        "df = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Define the target variable and feature columns\n",
        "target_column = 'clicked'\n",
        "feature_columns = ['opened', 'responded', 'subject_len', 'body_len']\n",
        "\n",
        "# Split features and target variable\n",
        "X, y = split_features_target(df, target_column, feature_columns)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = split_train_test(X, y)"
      ],
      "metadata": {
        "id": "7p2T5slhLX14"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trained_model1 = train_model1(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy, classification_rep, confusion_mat = evaluate_model(trained_model1, X_test, y_test)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\\n\", confusion_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYB-Dss2Rn00",
        "outputId": "1878c8d2-f92a-42b4-ec04-50a697ef3d6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5882352941176471\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.67      0.63         9\n",
            "           1       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.59        17\n",
            "   macro avg       0.59      0.58      0.58        17\n",
            "weighted avg       0.59      0.59      0.59        17\n",
            "\n",
            "Confusion Matrix:\n",
            " [[6 3]\n",
            " [4 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights and Considerations:**\n",
        "\n",
        "\n",
        "*   The confusion matrix shows that the model correctly predicted 6 instances of 'not clicked' and 4 instances of 'clicked'. However, it misclassified 3 instances of 'not clicked' as 'clicked' and 4 instances of 'clicked' as 'not clicked'.\n",
        "*   The model shows reasonable performance but has room for improvement, particularly in balancing precision and recall for both classes.\n",
        "*   Fine-tuning hyperparameters, experimenting with different algorithms, or adjusting the decision threshold may enhance model performance.\n",
        "*   Consideration of additional features or feature engineering could also contribute to better predictive capabilities.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eeIqLnoISm8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improving Model accuracy by adjusting the hyperparameters of the RandomForestClassifier and using a broader set of algorithms for comparison.\n",
        " We'll also include feature scaling for algorithms that benefit from it. Additionally, we'll address class imbalance by adjusting class weights.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v1iZHEzIR6vN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and train a machine learning model with adjustments to improve\n",
        "\n",
        "def train_model2(X_train, y_train, algorithm='random_forest'):\n",
        "    if algorithm == 'random_forest':\n",
        "        model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1))\n",
        "        ])\n",
        "    elif algorithm == 'svm':\n",
        "        model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', SVC(kernel='linear', class_weight='balanced'))\n",
        "        ])\n",
        "    elif algorithm == 'logistic_regression':\n",
        "        model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', LogisticRegression(class_weight='balanced'))\n",
        "        ])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid algorithm. Choose 'random_forest', 'svm', or 'logistic_regression'.\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Js8db7zoNLEB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model (Random Forest as an example, you can try SVM or Logistic Regression)\n",
        "trained_model2 = train_model2(X_train, y_train, algorithm='random_forest')\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy, classification_rep, confusion_mat = evaluate_model(trained_model2, X_test, y_test)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5yjCGlUNtBs",
        "outputId": "03cdbed4-fabf-46ec-d8be-0b388aeff59b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6470588235294118\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.78      0.70         9\n",
            "           1       0.67      0.50      0.57         8\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.65      0.64      0.64        17\n",
            "weighted avg       0.65      0.65      0.64        17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights and Considerations:**\n",
        "\n",
        "\n",
        "\n",
        "*   The model's accuracy has improved, particularly in identifying 'not clicked' instances.\n",
        "*   Precision for both classes has increased, indicating better correctness in predictions.\n",
        "*   The recall for 'clicked' instances remains a challenge, indicating potential areas for further improvement.\n"
      ],
      "metadata": {
        "id": "KFBn4DsOTeWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conclusion <a name=\"#conclusion\"></a>"
      ],
      "metadata": {
        "id": "FsK1LhS_T-gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The machine learning model has shown improvement in predicting email engagement, with the overall accuracy reaching approximately 65%. The precision and recall metrics have also shown enhancements, particularly in correctly identifying 'not clicked' instances. However, there is room for further improvement, especially in increasing recall for 'clicked' instances.\n",
        "\n",
        "In the upcoming detailed analysis report, we will delve into the finer nuances of the model's performance and explore comprehensive strategies for further improvement."
      ],
      "metadata": {
        "id": "yMPo3nfHUkZg"
      }
    }
  ]
}